{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 查看当前挂载的数据集目录, 该目录下的变更重启环境后会自动还原\n",
    "# View dataset directory. This directory will be recovered automatically after resetting environment. \n",
    "!ls /home/aistudio/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ashrae-energy-prediction.zip  test.csv\t\tweather_train.csv\r\n",
      "building_metadata.csv\t      train.csv\r\n",
      "sample_submission.csv\t      weather_test.csv\r\n"
     ]
    }
   ],
   "source": [
    "# 查看工作区文件, 该目录下的变更将会持久保存. 请及时清理不必要的文件, 避免加载过慢.\n",
    "# View personal work directory. All changes under this directory will be kept even after reset. Please clean unnecessary files in time to speed up environment loading.\n",
    "!ls /home/aistudio/work\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "请点击[此处](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576)查看本环境基本用法.  <br>\n",
    "Please click [here ](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576) for more detailed instructions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import lightgbm as lgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "import datetime\n",
    "import gc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20216100, 4)\n"
     ]
    }
   ],
   "source": [
    "# 加载数据\n",
    "train_data = pd.read_csv('work/train.csv')\n",
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20216100 entries, 0 to 20216099\n",
      "Data columns (total 4 columns):\n",
      "building_id      int64\n",
      "meter            int64\n",
      "timestamp        object\n",
      "meter_reading    float64\n",
      "dtypes: float64(1), int64(2), object(1)\n",
      "memory usage: 616.9+ MB\n"
     ]
    }
   ],
   "source": [
    "# 查看数据分布\n",
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>building_id</th>\n",
       "      <th>meter</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>meter_reading</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   building_id  meter            timestamp  meter_reading\n",
       "0            0      0  2016-01-01 00:00:00            0.0\n",
       "1            1      0  2016-01-01 00:00:00            0.0\n",
       "2            2      0  2016-01-01 00:00:00            0.0\n",
       "3            3      0  2016-01-01 00:00:00            0.0\n",
       "4            4      0  2016-01-01 00:00:00            0.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>building_id</th>\n",
       "      <th>meter</th>\n",
       "      <th>meter_reading</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.021610e+07</td>\n",
       "      <td>2.021610e+07</td>\n",
       "      <td>2.021610e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.992780e+02</td>\n",
       "      <td>6.624412e-01</td>\n",
       "      <td>2.117121e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.269133e+02</td>\n",
       "      <td>9.309921e-01</td>\n",
       "      <td>1.532356e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.930000e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.830000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>8.950000e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.877500e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.179000e+03</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.679840e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.448000e+03</td>\n",
       "      <td>3.000000e+00</td>\n",
       "      <td>2.190470e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        building_id         meter  meter_reading\n",
       "count  2.021610e+07  2.021610e+07   2.021610e+07\n",
       "mean   7.992780e+02  6.624412e-01   2.117121e+03\n",
       "std    4.269133e+02  9.309921e-01   1.532356e+05\n",
       "min    0.000000e+00  0.000000e+00   0.000000e+00\n",
       "25%    3.930000e+02  0.000000e+00   1.830000e+01\n",
       "50%    8.950000e+02  0.000000e+00   7.877500e+01\n",
       "75%    1.179000e+03  1.000000e+00   2.679840e+02\n",
       "max    1.448000e+03  3.000000e+00   2.190470e+07"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12060910, 4)\n",
      "(4182440, 4)\n",
      "(2708713, 4)\n",
      "(1264037, 4)\n"
     ]
    }
   ],
   "source": [
    "# 数据量太大，我们要想着合理划分使用，首先，看看train_data 中的列，电表代码，测试时间，电表值，我们可以把四种电表值分开来算\n",
    "train_data_meter0=train_data[train_data.meter==0]\n",
    "train_data_meter1=train_data[train_data.meter==1]\n",
    "train_data_meter2=train_data[train_data.meter==2]\n",
    "train_data_meter3=train_data[train_data.meter==3]\n",
    "print(train_data_meter0.shape)  # 电表id为1 的数据明显多于其他几个\n",
    "print(train_data_meter1.shape)\n",
    "print(train_data_meter2.shape)\n",
    "print(train_data_meter3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# remove outliers 去除离群值\n",
    "train_df = train_data[ train_data['building_id']!=1099]\n",
    "train_df = train_df.query('not (building_id <= 104 & meter ==0 & timestamp <=\"2016-05-20\")')\n",
    "\n",
    "building_df = pd.read_csv('work/building_metadata.csv')\n",
    "weather_df = pd.read_csv('work/weather_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Utility Functions\n",
    "def fill_weather_dataset(weather_df):\n",
    "    \n",
    "    # Find Missing Dates\n",
    "    time_format = \"%Y-%m-%d %H:%M:%S\"\n",
    "    start_date = datetime.datetime.strptime(weather_df['timestamp'].min(),time_format)\n",
    "    end_date = datetime.datetime.strptime(weather_df['timestamp'].max(),time_format)\n",
    "    total_hours = int(((end_date - start_date).total_seconds() + 3600) / 3600)\n",
    "    hours_list = [(end_date - datetime.timedelta(hours=x)).strftime(time_format) for x in range(total_hours)]\n",
    "\n",
    "    missing_hours = []\n",
    "    for site_id in range(16):\n",
    "        site_hours = np.array(weather_df[weather_df['site_id'] == site_id]['timestamp'])\n",
    "        new_rows = pd.DataFrame(np.setdiff1d(hours_list,site_hours),columns=['timestamp'])\n",
    "        new_rows['site_id'] = site_id\n",
    "        weather_df = pd.concat([weather_df,new_rows])\n",
    "\n",
    "        weather_df = weather_df.reset_index(drop=True)           \n",
    "\n",
    "    # Add new Features\n",
    "    weather_df[\"datetime\"] = pd.to_datetime(weather_df[\"timestamp\"])\n",
    "    weather_df[\"day\"] = weather_df[\"datetime\"].dt.day\n",
    "    weather_df[\"week\"] = weather_df[\"datetime\"].dt.week\n",
    "    weather_df[\"month\"] = weather_df[\"datetime\"].dt.month\n",
    "    \n",
    "    # Reset Index for Fast Update\n",
    "    weather_df = weather_df.set_index(['site_id','day','month'])\n",
    "\n",
    "    air_temperature_filler = pd.DataFrame(weather_df.groupby(['site_id','day','month'])['air_temperature'].mean(),columns=[\"air_temperature\"])\n",
    "    weather_df.update(air_temperature_filler,overwrite=False)\n",
    "\n",
    "    # Step 1\n",
    "    cloud_coverage_filler = weather_df.groupby(['site_id','day','month'])['cloud_coverage'].mean()\n",
    "    # Step 2\n",
    "    cloud_coverage_filler = pd.DataFrame(cloud_coverage_filler.fillna(method='ffill'),columns=[\"cloud_coverage\"])\n",
    "\n",
    "    weather_df.update(cloud_coverage_filler,overwrite=False)\n",
    "\n",
    "    due_temperature_filler = pd.DataFrame(weather_df.groupby(['site_id','day','month'])['dew_temperature'].mean(),columns=[\"dew_temperature\"])\n",
    "    weather_df.update(due_temperature_filler,overwrite=False)\n",
    "\n",
    "    # Step 1\n",
    "    sea_level_filler = weather_df.groupby(['site_id','day','month'])['sea_level_pressure'].mean()\n",
    "    # Step 2\n",
    "    sea_level_filler = pd.DataFrame(sea_level_filler.fillna(method='ffill'),columns=['sea_level_pressure'])\n",
    "\n",
    "    weather_df.update(sea_level_filler,overwrite=False)\n",
    "\n",
    "    wind_direction_filler =  pd.DataFrame(weather_df.groupby(['site_id','day','month'])['wind_direction'].mean(),columns=['wind_direction'])\n",
    "    weather_df.update(wind_direction_filler,overwrite=False)\n",
    "\n",
    "    wind_speed_filler =  pd.DataFrame(weather_df.groupby(['site_id','day','month'])['wind_speed'].mean(),columns=['wind_speed'])\n",
    "    weather_df.update(wind_speed_filler,overwrite=False)\n",
    "\n",
    "    # Step 1\n",
    "    precip_depth_filler = weather_df.groupby(['site_id','day','month'])['precip_depth_1_hr'].mean()\n",
    "    # Step 2\n",
    "    precip_depth_filler = pd.DataFrame(precip_depth_filler.fillna(method='ffill'),columns=['precip_depth_1_hr'])\n",
    "\n",
    "    weather_df.update(precip_depth_filler,overwrite=False)\n",
    "\n",
    "    weather_df = weather_df.reset_index()\n",
    "    weather_df = weather_df.drop(['datetime','day','week','month'],axis=1)\n",
    "        \n",
    "    return weather_df\n",
    "\n",
    "# Original code from https://www.kaggle.com/gemartin/load-data-reduce-memory-usage by @gemartin\n",
    "\n",
    "from pandas.api.types import is_datetime64_any_dtype as is_datetime\n",
    "from pandas.api.types import is_categorical_dtype\n",
    "\n",
    "def reduce_mem_usage(df, use_float16=False):\n",
    "    \"\"\"\n",
    "    Iterate through all the columns of a dataframe and modify the data type to reduce memory usage.        \n",
    "    \"\"\"\n",
    "    \n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print(\"Memory usage of dataframe is {:.2f} MB\".format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        if is_datetime(df[col]) or is_categorical_dtype(df[col]):\n",
    "            continue\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == \"int\":\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if use_float16 and c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            df[col] = df[col].astype(\"category\")\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print(\"Memory usage after optimization is: {:.2f} MB\".format(end_mem))\n",
    "    print(\"Decreased by {:.1f}%\".format(100 * (start_mem - end_mem) / start_mem))\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def features_engineering(df):\n",
    "    \n",
    "    # Sort by timestamp\n",
    "    df.sort_values(\"timestamp\")\n",
    "    df.reset_index(drop=True)\n",
    "    \n",
    "    # Add more features\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"],format=\"%Y-%m-%d %H:%M:%S\")\n",
    "    df[\"hour\"] = df[\"timestamp\"].dt.hour\n",
    "    df[\"weekend\"] = df[\"timestamp\"].dt.weekday\n",
    "    holidays = [\"2016-01-01\", \"2016-01-18\", \"2016-02-15\", \"2016-05-30\", \"2016-07-04\",\n",
    "                    \"2016-09-05\", \"2016-10-10\", \"2016-11-11\", \"2016-11-24\", \"2016-12-26\",\n",
    "                    \"2017-01-02\", \"2017-01-16\", \"2017-02-20\", \"2017-05-29\", \"2017-07-04\",\n",
    "                    \"2017-09-04\", \"2017-10-09\", \"2017-11-10\", \"2017-11-23\", \"2017-12-25\",\n",
    "                    \"2018-01-01\", \"2018-01-15\", \"2018-02-19\", \"2018-05-28\", \"2018-07-04\",\n",
    "                    \"2018-09-03\", \"2018-10-08\", \"2018-11-12\", \"2018-11-22\", \"2018-12-25\",\n",
    "                    \"2019-01-01\"]\n",
    "    df[\"is_holiday\"] = (df.timestamp.isin(holidays)).astype(int)\n",
    "    df['square_feet'] =  np.log1p(df['square_feet'])\n",
    "    \n",
    "    # Remove Unused Columns\n",
    "    drop = [\"timestamp\",\"sea_level_pressure\", \"wind_direction\", \"wind_speed\",\"year_built\",\"floor_count\"]\n",
    "    df = df.drop(drop, axis=1)\n",
    "    gc.collect()\n",
    "    \n",
    "    # Encode Categorical Data\n",
    "    le = LabelEncoder()\n",
    "    df[\"primary_use\"] = le.fit_transform(df[\"primary_use\"])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/ipykernel_launcher.py:16: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "# Fill Weather Information\n",
    "# using this kernel to handle missing weather information\n",
    "weather_df = fill_weather_dataset(weather_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 757.31 MB\n",
      "Memory usage after optimization is: 322.24 MB\n",
      "Decreased by 57.4%\n",
      "Memory usage of dataframe is 0.07 MB\n",
      "Memory usage after optimization is: 0.02 MB\n",
      "Decreased by 73.8%\n",
      "Memory usage of dataframe is 9.60 MB\n",
      "Memory usage after optimization is: 2.65 MB\n",
      "Decreased by 72.4%\n"
     ]
    }
   ],
   "source": [
    "# Memory reduction\n",
    "train_df = reduce_mem_usage(train_df,use_float16=True)\n",
    "building_df = reduce_mem_usage(building_df,use_float16=True)\n",
    "weather_df = reduce_mem_usage(weather_df,use_float16=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge Data   We need to add building and weather information into training dataset.\n",
    "train_df = train_df.merge(buildinf_df,left_on='building_id',right_on='building_id',how='left')\n",
    "train_df = train_df.merge(weather_df,how='left',left_on=['site_id','timestamp'],right_on=['site_id','timestamp'])\n",
    "del weather_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Features Engineering\n",
    "train_df = features_engineering(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>building_id</th>\n",
       "      <th>meter</th>\n",
       "      <th>meter_reading</th>\n",
       "      <th>site_id</th>\n",
       "      <th>primary_use</th>\n",
       "      <th>square_feet</th>\n",
       "      <th>air_temperature</th>\n",
       "      <th>cloud_coverage</th>\n",
       "      <th>dew_temperature</th>\n",
       "      <th>precip_depth_1_hr</th>\n",
       "      <th>hour</th>\n",
       "      <th>weekend</th>\n",
       "      <th>is_holiday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>105</td>\n",
       "      <td>0</td>\n",
       "      <td>23.303600</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10.832181</td>\n",
       "      <td>3.800781</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.400391</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>106</td>\n",
       "      <td>0</td>\n",
       "      <td>0.374600</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8.589514</td>\n",
       "      <td>3.800781</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.400391</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>106</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8.589514</td>\n",
       "      <td>3.800781</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.400391</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>107</td>\n",
       "      <td>0</td>\n",
       "      <td>175.184006</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.487946</td>\n",
       "      <td>3.800781</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.400391</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>108</td>\n",
       "      <td>0</td>\n",
       "      <td>91.265297</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.309352</td>\n",
       "      <td>3.800781</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.400391</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>109</td>\n",
       "      <td>0</td>\n",
       "      <td>80.930000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10.950736</td>\n",
       "      <td>3.800781</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.400391</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>109</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10.950736</td>\n",
       "      <td>3.800781</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.400391</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>110</td>\n",
       "      <td>0</td>\n",
       "      <td>86.228302</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10.233331</td>\n",
       "      <td>3.800781</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.400391</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>111</td>\n",
       "      <td>0</td>\n",
       "      <td>167.391998</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.681309</td>\n",
       "      <td>3.800781</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.400391</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>112</td>\n",
       "      <td>0</td>\n",
       "      <td>10.274800</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10.379939</td>\n",
       "      <td>3.800781</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.400391</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>112</td>\n",
       "      <td>3</td>\n",
       "      <td>96.977997</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10.379939</td>\n",
       "      <td>3.800781</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.400391</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>113</td>\n",
       "      <td>0</td>\n",
       "      <td>159.643005</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.517734</td>\n",
       "      <td>3.800781</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.400391</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>113</td>\n",
       "      <td>3</td>\n",
       "      <td>19.597000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.517734</td>\n",
       "      <td>3.800781</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.400391</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>114</td>\n",
       "      <td>0</td>\n",
       "      <td>324.750000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.847138</td>\n",
       "      <td>3.800781</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.400391</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>114</td>\n",
       "      <td>3</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.847138</td>\n",
       "      <td>3.800781</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.400391</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>115</td>\n",
       "      <td>0</td>\n",
       "      <td>201.542999</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.773110</td>\n",
       "      <td>3.800781</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.400391</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>116</td>\n",
       "      <td>0</td>\n",
       "      <td>69.300003</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10.525837</td>\n",
       "      <td>3.800781</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.400391</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>117</td>\n",
       "      <td>0</td>\n",
       "      <td>16.306101</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9.647950</td>\n",
       "      <td>3.800781</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.400391</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>117</td>\n",
       "      <td>3</td>\n",
       "      <td>19.680901</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9.647950</td>\n",
       "      <td>3.800781</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.400391</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "      <td>117.199997</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.837303</td>\n",
       "      <td>3.800781</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.400391</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    building_id  meter  meter_reading  site_id  primary_use  square_feet  \\\n",
       "0           105      0      23.303600        1            0    10.832181   \n",
       "1           106      0       0.374600        1            0     8.589514   \n",
       "2           106      3       0.000000        1            0     8.589514   \n",
       "3           107      0     175.184006        1            0    11.487946   \n",
       "4           108      0      91.265297        1            0    11.309352   \n",
       "5           109      0      80.930000        1            0    10.950736   \n",
       "6           109      3       0.000000        1            0    10.950736   \n",
       "7           110      0      86.228302        1            0    10.233331   \n",
       "8           111      0     167.391998        1            0    11.681309   \n",
       "9           112      0      10.274800        1            0    10.379939   \n",
       "10          112      3      96.977997        1            0    10.379939   \n",
       "11          113      0     159.643005        1            0    11.517734   \n",
       "12          113      3      19.597000        1            0    11.517734   \n",
       "13          114      0     324.750000        1            0    11.847138   \n",
       "14          114      3     100.000000        1            0    11.847138   \n",
       "15          115      0     201.542999        1            0    11.773110   \n",
       "16          116      0      69.300003        1            0    10.525837   \n",
       "17          117      0      16.306101        1            0     9.647950   \n",
       "18          117      3      19.680901        1            0     9.647950   \n",
       "19          118      0     117.199997        1            0    11.837303   \n",
       "\n",
       "    air_temperature  cloud_coverage  dew_temperature  precip_depth_1_hr  hour  \\\n",
       "0          3.800781             NaN         2.400391                NaN     0   \n",
       "1          3.800781             NaN         2.400391                NaN     0   \n",
       "2          3.800781             NaN         2.400391                NaN     0   \n",
       "3          3.800781             NaN         2.400391                NaN     0   \n",
       "4          3.800781             NaN         2.400391                NaN     0   \n",
       "5          3.800781             NaN         2.400391                NaN     0   \n",
       "6          3.800781             NaN         2.400391                NaN     0   \n",
       "7          3.800781             NaN         2.400391                NaN     0   \n",
       "8          3.800781             NaN         2.400391                NaN     0   \n",
       "9          3.800781             NaN         2.400391                NaN     0   \n",
       "10         3.800781             NaN         2.400391                NaN     0   \n",
       "11         3.800781             NaN         2.400391                NaN     0   \n",
       "12         3.800781             NaN         2.400391                NaN     0   \n",
       "13         3.800781             NaN         2.400391                NaN     0   \n",
       "14         3.800781             NaN         2.400391                NaN     0   \n",
       "15         3.800781             NaN         2.400391                NaN     0   \n",
       "16         3.800781             NaN         2.400391                NaN     0   \n",
       "17         3.800781             NaN         2.400391                NaN     0   \n",
       "18         3.800781             NaN         2.400391                NaN     0   \n",
       "19         3.800781             NaN         2.400391                NaN     0   \n",
       "\n",
       "    weekend  is_holiday  \n",
       "0         4           1  \n",
       "1         4           1  \n",
       "2         4           1  \n",
       "3         4           1  \n",
       "4         4           1  \n",
       "5         4           1  \n",
       "6         4           1  \n",
       "7         4           1  \n",
       "8         4           1  \n",
       "9         4           1  \n",
       "10        4           1  \n",
       "11        4           1  \n",
       "12        4           1  \n",
       "13        4           1  \n",
       "14        4           1  \n",
       "15        4           1  \n",
       "16        4           1  \n",
       "17        4           1  \n",
       "18        4           1  \n",
       "19        4           1  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Features & Target Varibales\n",
    "target = np.log1p(train_df[\"meter_reading\"])\n",
    "features = train_df.drop('meter_reading', axis = 1)\n",
    "del train_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 1.11621\tvalid_1's rmse: 1.2655\n",
      "[50]\ttraining's rmse: 0.901102\tvalid_1's rmse: 1.13574\n",
      "[75]\ttraining's rmse: 0.833216\tvalid_1's rmse: 1.11974\n",
      "[100]\ttraining's rmse: 0.797454\tvalid_1's rmse: 1.1202\n",
      "[125]\ttraining's rmse: 0.773428\tvalid_1's rmse: 1.12349\n",
      "Early stopping, best iteration is:\n",
      "[87]\ttraining's rmse: 0.814148\tvalid_1's rmse: 1.1184\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 1.12064\tvalid_1's rmse: 1.22349\n",
      "[50]\ttraining's rmse: 0.905981\tvalid_1's rmse: 1.07241\n",
      "[75]\ttraining's rmse: 0.847502\tvalid_1's rmse: 1.04857\n",
      "[100]\ttraining's rmse: 0.817678\tvalid_1's rmse: 1.0441\n",
      "[125]\ttraining's rmse: 0.795745\tvalid_1's rmse: 1.04443\n",
      "[150]\ttraining's rmse: 0.780554\tvalid_1's rmse: 1.04607\n",
      "Early stopping, best iteration is:\n",
      "[103]\ttraining's rmse: 0.815595\tvalid_1's rmse: 1.04302\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 1.0933\tvalid_1's rmse: 1.27166\n",
      "[50]\ttraining's rmse: 0.856492\tvalid_1's rmse: 1.1534\n",
      "[75]\ttraining's rmse: 0.785067\tvalid_1's rmse: 1.14483\n",
      "[100]\ttraining's rmse: 0.750169\tvalid_1's rmse: 1.148\n",
      "Early stopping, best iteration is:\n",
      "[71]\ttraining's rmse: 0.79201\tvalid_1's rmse: 1.14394\n"
     ]
    }
   ],
   "source": [
    "# KFold LightGBM Model\n",
    "categorical_features = [\"building_id\", \"site_id\", \"meter\", \"primary_use\", \"is_holiday\", \"weekend\"]\n",
    "params = {\n",
    "    \"objective\": \"regression\",\n",
    "    \"boosting\": \"gbdt\",\n",
    "    \"num_leaves\": 1280,\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"feature_fraction\": 0.85,\n",
    "    \"reg_lambda\": 2,\n",
    "    \"metric\": \"rmse\",\n",
    "}\n",
    "\n",
    "kf = KFold(n_splits=3)\n",
    "models = []\n",
    "for train_index,test_index in kf.split(features):\n",
    "    train_features = features.loc[train_index]\n",
    "    train_target = target.loc[train_index]\n",
    "    \n",
    "    test_features = features.loc[test_index]\n",
    "    test_target = target.loc[test_index]\n",
    "    \n",
    "    d_training = lgb.Dataset(train_features, label=train_target,categorical_feature=categorical_features, free_raw_data=False)\n",
    "    d_test = lgb.Dataset(test_features, label=test_target,categorical_feature=categorical_features, free_raw_data=False)\n",
    "    \n",
    "    model = lgb.train(params, train_set=d_training, num_boost_round=1000, valid_sets=[d_training,d_test], verbose_eval=25, early_stopping_rounds=50)\n",
    "    models.append(model)\n",
    "    del train_features, train_target, test_features, test_target, d_training, d_test\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del features, target\r\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 954.38 MB\n",
      "Memory usage after optimization is: 199.59 MB\n",
      "Decreased by 79.1%\n"
     ]
    }
   ],
   "source": [
    "# Load test data\r\n",
    "test_df = pd.read_csv('work/test.csv')\r\n",
    "row_ids = test_df[\"row_id\"]\r\n",
    "test_df.drop(\"row_id\", axis=1, inplace=True)\r\n",
    "test_df = reduce_mem_usage(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "167"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge Building Data\n",
    "test_df = test_df.merge(building_df,left_on='building_id',right_on='building_id',how='left')\n",
    "del building_df\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/ipykernel_launcher.py:16: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 19.25 MB\n",
      "Memory usage after optimization is: 9.05 MB\n",
      "Decreased by 53.0%\n"
     ]
    }
   ],
   "source": [
    "# Fill Weather Information\n",
    "weather_df = pd.read_csv('work/weather_test.csv')\n",
    "weather_df = fill_weather_dataset(weather_df)\n",
    "weather_df = reduce_mem_usage(weather_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "378"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge Weather Data\n",
    "test_df = test_df.merge(weather_df,how='left',on=['timestamp','site_id'])\n",
    "del weather_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Features Engineering\n",
    "test_df = features_engineering(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/ipykernel_launcher.py:4: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# prediction\n",
    "results = []\n",
    "for model in models:\n",
    "    if  results == []:\n",
    "        results = np.expm1(model.predict(test_df, num_iteration=model.best_iteration)) / len(models)\n",
    "    else:\n",
    "        results += np.expm1(model.predict(test_df, num_iteration=model.best_iteration)) / len(models)\n",
    "    del model\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del test_df, models\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# submission\n",
    "results_df = pd.DataFrame({\"row_id\": row_ids, \"meter_reading\": np.clip(results, 0, a_max=None)})\n",
    "del row_ids,results\n",
    "gc.collect()\n",
    "results_df.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>meter_reading</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>193.945995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>90.009323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>15.193782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>262.514755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1135.918649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>24.449538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>98.006903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>437.700966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>356.060668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>328.046842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>59.418115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>14.107324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>1010.730244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>351.950997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>182.066440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>197.396449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>57.146974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>279.549073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>505.057883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>206.146900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    row_id  meter_reading\n",
       "0        0     193.945995\n",
       "1        1      90.009323\n",
       "2        2      15.193782\n",
       "3        3     262.514755\n",
       "4        4    1135.918649\n",
       "5        5      24.449538\n",
       "6        6      98.006903\n",
       "7        7     437.700966\n",
       "8        8     356.060668\n",
       "9        9     328.046842\n",
       "10      10      59.418115\n",
       "11      11      14.107324\n",
       "12      12    1010.730244\n",
       "13      13     351.950997\n",
       "14      14     182.066440\n",
       "15      15     197.396449\n",
       "16      16      57.146974\n",
       "17      17     279.549073\n",
       "18      18     505.057883\n",
       "19      19     206.146900"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.head(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 1.6.0 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
