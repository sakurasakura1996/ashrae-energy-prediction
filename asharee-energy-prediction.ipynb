{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import lightgbm as lgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "import datetime\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "(20216100, 4)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# 加载数据\n",
    "train_data = pd.read_csv('F:\\deeplearning_dataset\\\\ashrae-energy-prediction\\\\train.csv')\n",
    "print(train_data.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 数据量太大，我们要想着合理划分使用，首先，看看train_data 中的列，电表代码，测试时间，电表值，我们可以把四种电表值分开来算\n",
    "train_data_meter0=train_data[train_data.meter==0]\n",
    "train_data_meter1=train_data[train_data.meter==1]\n",
    "train_data_meter2=train_data[train_data.meter==2]\n",
    "train_data_meter3=train_data[train_data.meter==3]\n",
    "print(train_data_meter0.shape)  # 电表id为1 的数据明显多于其他几个\n",
    "print(train_data_meter1.shape)\n",
    "print(train_data_meter2.shape)\n",
    "print(train_data_meter3.shape)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# remove outliers 去除离群值\n",
    "train_df = train_data[ train_data['building_id']!=1099]\n",
    "gc.collect()\n",
    "train_df = train_df.query('not (building_id <= 104 & meter ==0 & timestamp <=\"2016-05-20\")')\n",
    "building_df = pd.read_csv('F:\\deeplearning_dataset\\\\ashrae-energy-prediction\\\\building_metadata.csv')\n",
    "weather_df = pd.read_csv('F:\\deeplearning_dataset\\\\ashrae-energy-prediction\\weather_train.csv')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# Utility Functions\n",
    "def fill_weather_dataset(weather_df):\n",
    "    \n",
    "    # Find Missing Dates\n",
    "    time_format = \"%Y-%m-%d %H:%M:%S\"\n",
    "    start_date = datetime.datetime.strptime(weather_df['timestamp'].min(),time_format)\n",
    "    end_date = datetime.datetime.strptime(weather_df['timestamp'].max(),time_format)\n",
    "    total_hours = int(((end_date - start_date).total_seconds() + 3600) / 3600)\n",
    "    hours_list = [(end_date - datetime.timedelta(hours=x)).strftime(time_format) for x in range(total_hours)]\n",
    "\n",
    "    missing_hours = []\n",
    "    for site_id in range(16):\n",
    "        site_hours = np.array(weather_df[weather_df['site_id'] == site_id]['timestamp'])\n",
    "        new_rows = pd.DataFrame(np.setdiff1d(hours_list,site_hours),columns=['timestamp'])\n",
    "        new_rows['site_id'] = site_id\n",
    "        weather_df = pd.concat([weather_df,new_rows])\n",
    "\n",
    "        weather_df = weather_df.reset_index(drop=True)           \n",
    "\n",
    "    # Add new Features\n",
    "    weather_df[\"datetime\"] = pd.to_datetime(weather_df[\"timestamp\"])\n",
    "    weather_df[\"day\"] = weather_df[\"datetime\"].dt.day\n",
    "    weather_df[\"week\"] = weather_df[\"datetime\"].dt.week\n",
    "    weather_df[\"month\"] = weather_df[\"datetime\"].dt.month\n",
    "    \n",
    "    # Reset Index for Fast Update\n",
    "    weather_df = weather_df.set_index(['site_id','day','month'])\n",
    "\n",
    "    air_temperature_filler = pd.DataFrame(weather_df.groupby(['site_id','day','month'])['air_temperature'].mean(),columns=[\"air_temperature\"])\n",
    "    weather_df.update(air_temperature_filler,overwrite=False)\n",
    "\n",
    "    # Step 1\n",
    "    cloud_coverage_filler = weather_df.groupby(['site_id','day','month'])['cloud_coverage'].mean()\n",
    "    # Step 2\n",
    "    cloud_coverage_filler = pd.DataFrame(cloud_coverage_filler.fillna(method='ffill'),columns=[\"cloud_coverage\"])\n",
    "\n",
    "    weather_df.update(cloud_coverage_filler,overwrite=False)\n",
    "\n",
    "    due_temperature_filler = pd.DataFrame(weather_df.groupby(['site_id','day','month'])['dew_temperature'].mean(),columns=[\"dew_temperature\"])\n",
    "    weather_df.update(due_temperature_filler,overwrite=False)\n",
    "\n",
    "    # Step 1\n",
    "    sea_level_filler = weather_df.groupby(['site_id','day','month'])['sea_level_pressure'].mean()\n",
    "    # Step 2\n",
    "    sea_level_filler = pd.DataFrame(sea_level_filler.fillna(method='ffill'),columns=['sea_level_pressure'])\n",
    "\n",
    "    weather_df.update(sea_level_filler,overwrite=False)\n",
    "\n",
    "    wind_direction_filler =  pd.DataFrame(weather_df.groupby(['site_id','day','month'])['wind_direction'].mean(),columns=['wind_direction'])\n",
    "    weather_df.update(wind_direction_filler,overwrite=False)\n",
    "\n",
    "    wind_speed_filler =  pd.DataFrame(weather_df.groupby(['site_id','day','month'])['wind_speed'].mean(),columns=['wind_speed'])\n",
    "    weather_df.update(wind_speed_filler,overwrite=False)\n",
    "\n",
    "    # Step 1\n",
    "    precip_depth_filler = weather_df.groupby(['site_id','day','month'])['precip_depth_1_hr'].mean()\n",
    "    # Step 2\n",
    "    precip_depth_filler = pd.DataFrame(precip_depth_filler.fillna(method='ffill'),columns=['precip_depth_1_hr'])\n",
    "    weather_df.update(precip_depth_filler,overwrite=False)\n",
    "    weather_df = weather_df.reset_index()\n",
    "    weather_df = weather_df.drop(['datetime','day','week','month'],axis=1)    \n",
    "    return weather_df\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# Original code from https://www.kaggle.com/gemartin/load-data-reduce-memory-usage by @gemartin\n",
    "from pandas.api.types import is_datetime64_any_dtype as is_datetime\n",
    "from pandas.api.types import is_categorical_dtype\n",
    "\n",
    "def reduce_mem_usage(df, use_float16=False):\n",
    "    \"\"\"\n",
    "    Iterate through all the columns of a dataframe and modify the data type to reduce memory usage.        \n",
    "    \"\"\"\n",
    "    \n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print(\"Memory usage of dataframe is {:.2f} MB\".format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        if is_datetime(df[col]) or is_categorical_dtype(df[col]):\n",
    "            continue\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == \"int\":\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if use_float16 and c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            df[col] = df[col].astype(\"category\")\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print(\"Memory usage after optimization is: {:.2f} MB\".format(end_mem))\n",
    "    print(\"Decreased by {:.1f}%\".format(100 * (start_mem - end_mem) / start_mem))\n",
    "    return df\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def features_engineering(df):\n",
    "    \n",
    "    # Sort by timestamp\n",
    "    df.sort_values(\"timestamp\")\n",
    "    df.reset_index(drop=True)\n",
    "    # Add more features\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"],format=\"%Y-%m-%d %H:%M:%S\")\n",
    "    df[\"hour\"] = df[\"timestamp\"].dt.hour\n",
    "    df[\"weekend\"] = df[\"timestamp\"].dt.weekday\n",
    "    holidays = [\"2016-01-01\", \"2016-01-18\", \"2016-02-15\", \"2016-05-30\", \"2016-07-04\",\n",
    "                    \"2016-09-05\", \"2016-10-10\", \"2016-11-11\", \"2016-11-24\", \"2016-12-26\",\n",
    "                    \"2017-01-02\", \"2017-01-16\", \"2017-02-20\", \"2017-05-29\", \"2017-07-04\",\n",
    "                    \"2017-09-04\", \"2017-10-09\", \"2017-11-10\", \"2017-11-23\", \"2017-12-25\",\n",
    "                    \"2018-01-01\", \"2018-01-15\", \"2018-02-19\", \"2018-05-28\", \"2018-07-04\",\n",
    "                    \"2018-09-03\", \"2018-10-08\", \"2018-11-12\", \"2018-11-22\", \"2018-12-25\",\n",
    "                    \"2019-01-01\"]\n",
    "    df[\"is_holiday\"] = (df.timestamp.isin(holidays)).astype(int)\n",
    "    df['square_feet'] =  np.log1p(df['square_feet'])\n",
    "    # Remove Unused Columns\n",
    "    drop = [\"timestamp\",\"sea_level_pressure\", \"wind_direction\", \"wind_speed\",\"year_built\",\"floor_count\"]\n",
    "    df = df.drop(drop, axis=1)\n",
    "    gc.collect()\n",
    "    # Encode Categorical Data\n",
    "    le = LabelEncoder()\n",
    "    df[\"primary_use\"] = le.fit_transform(df[\"primary_use\"])\n",
    "    return df\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "c:\\users\\administrator\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:16: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\nof pandas will change to not sort by default.\n\nTo accept the future behavior, pass 'sort=False'.\n\nTo retain the current behavior and silence the warning, pass 'sort=True'.\n\n  app.launch_new_instance()\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# Fill Weather Information\n",
    "# using this kernel to handle missing weather information\n",
    "weather_df = fill_weather_dataset(weather_df)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Memory usage of dataframe is 757.31 MB\n",
      "Memory usage after optimization is: 322.24 MB\nDecreased by 57.4%\nMemory usage of dataframe is 0.07 MB\nMemory usage after optimization is: 0.02 MB\nDecreased by 73.8%\nMemory usage of dataframe is 9.65 MB\nMemory usage after optimization is: 2.66 MB\nDecreased by 72.5%\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# Memory reduction\n",
    "train_df = reduce_mem_usage(train_df,use_float16=True)\n",
    "building_df = reduce_mem_usage(building_df,use_float16=True)\n",
    "weather_df = reduce_mem_usage(weather_df,use_float16=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "121"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 13
    }
   ],
   "source": [
    "# Merge Data   We need to add building and weather information into training dataset.\n",
    "train_df = train_df.merge(building_df,left_on='building_id',right_on='building_id',how='left')\n",
    "train_df = train_df.merge(weather_df,how='left',left_on=['site_id','timestamp'],right_on=['site_id','timestamp'])\n",
    "del weather_df\n",
    "gc.collect()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# Features Engineering\n",
    "train_df = features_engineering(train_df)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "    building_id  meter  meter_reading  site_id  primary_use  square_feet  \\\n0           105      0      23.303600        1            0    10.832181   \n1           106      0       0.374600        1            0     8.589514   \n2           106      3       0.000000        1            0     8.589514   \n3           107      0     175.184006        1            0    11.487946   \n4           108      0      91.265297        1            0    11.309352   \n5           109      0      80.930000        1            0    10.950736   \n6           109      3       0.000000        1            0    10.950736   \n7           110      0      86.228302        1            0    10.233331   \n8           111      0     167.391998        1            0    11.681309   \n9           112      0      10.274800        1            0    10.379939   \n10          112      3      96.977997        1            0    10.379939   \n11          113      0     159.643005        1            0    11.517734   \n12          113      3      19.597000        1            0    11.517734   \n13          114      0     324.750000        1            0    11.847138   \n14          114      3     100.000000        1            0    11.847138   \n15          115      0     201.542999        1            0    11.773110   \n16          116      0      69.300003        1            0    10.525837   \n17          117      0      16.306101        1            0     9.647950   \n18          117      3      19.680901        1            0     9.647950   \n19          118      0     117.199997        1            0    11.837303   \n\n    air_temperature  cloud_coverage  dew_temperature  precip_depth_1_hr  hour  \\\n0          3.800781             0.0         2.400391                0.0     0   \n1          3.800781             0.0         2.400391                0.0     0   \n2          3.800781             0.0         2.400391                0.0     0   \n3          3.800781             0.0         2.400391                0.0     0   \n4          3.800781             0.0         2.400391                0.0     0   \n5          3.800781             0.0         2.400391                0.0     0   \n6          3.800781             0.0         2.400391                0.0     0   \n7          3.800781             0.0         2.400391                0.0     0   \n8          3.800781             0.0         2.400391                0.0     0   \n9          3.800781             0.0         2.400391                0.0     0   \n10         3.800781             0.0         2.400391                0.0     0   \n11         3.800781             0.0         2.400391                0.0     0   \n12         3.800781             0.0         2.400391                0.0     0   \n13         3.800781             0.0         2.400391                0.0     0   \n14         3.800781             0.0         2.400391                0.0     0   \n15         3.800781             0.0         2.400391                0.0     0   \n16         3.800781             0.0         2.400391                0.0     0   \n17         3.800781             0.0         2.400391                0.0     0   \n18         3.800781             0.0         2.400391                0.0     0   \n19         3.800781             0.0         2.400391                0.0     0   \n\n    weekend  is_holiday  \n0         4           0  \n1         4           0  \n2         4           0  \n3         4           0  \n4         4           0  \n5         4           0  \n6         4           0  \n7         4           0  \n8         4           0  \n9         4           0  \n10        4           0  \n11        4           0  \n12        4           0  \n13        4           0  \n14        4           0  \n15        4           0  \n16        4           0  \n17        4           0  \n18        4           0  \n19        4           0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>building_id</th>\n      <th>meter</th>\n      <th>meter_reading</th>\n      <th>site_id</th>\n      <th>primary_use</th>\n      <th>square_feet</th>\n      <th>air_temperature</th>\n      <th>cloud_coverage</th>\n      <th>dew_temperature</th>\n      <th>precip_depth_1_hr</th>\n      <th>hour</th>\n      <th>weekend</th>\n      <th>is_holiday</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>105</td>\n      <td>0</td>\n      <td>23.303600</td>\n      <td>1</td>\n      <td>0</td>\n      <td>10.832181</td>\n      <td>3.800781</td>\n      <td>0.0</td>\n      <td>2.400391</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>106</td>\n      <td>0</td>\n      <td>0.374600</td>\n      <td>1</td>\n      <td>0</td>\n      <td>8.589514</td>\n      <td>3.800781</td>\n      <td>0.0</td>\n      <td>2.400391</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>106</td>\n      <td>3</td>\n      <td>0.000000</td>\n      <td>1</td>\n      <td>0</td>\n      <td>8.589514</td>\n      <td>3.800781</td>\n      <td>0.0</td>\n      <td>2.400391</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>107</td>\n      <td>0</td>\n      <td>175.184006</td>\n      <td>1</td>\n      <td>0</td>\n      <td>11.487946</td>\n      <td>3.800781</td>\n      <td>0.0</td>\n      <td>2.400391</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>108</td>\n      <td>0</td>\n      <td>91.265297</td>\n      <td>1</td>\n      <td>0</td>\n      <td>11.309352</td>\n      <td>3.800781</td>\n      <td>0.0</td>\n      <td>2.400391</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>109</td>\n      <td>0</td>\n      <td>80.930000</td>\n      <td>1</td>\n      <td>0</td>\n      <td>10.950736</td>\n      <td>3.800781</td>\n      <td>0.0</td>\n      <td>2.400391</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>109</td>\n      <td>3</td>\n      <td>0.000000</td>\n      <td>1</td>\n      <td>0</td>\n      <td>10.950736</td>\n      <td>3.800781</td>\n      <td>0.0</td>\n      <td>2.400391</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>110</td>\n      <td>0</td>\n      <td>86.228302</td>\n      <td>1</td>\n      <td>0</td>\n      <td>10.233331</td>\n      <td>3.800781</td>\n      <td>0.0</td>\n      <td>2.400391</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>111</td>\n      <td>0</td>\n      <td>167.391998</td>\n      <td>1</td>\n      <td>0</td>\n      <td>11.681309</td>\n      <td>3.800781</td>\n      <td>0.0</td>\n      <td>2.400391</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>112</td>\n      <td>0</td>\n      <td>10.274800</td>\n      <td>1</td>\n      <td>0</td>\n      <td>10.379939</td>\n      <td>3.800781</td>\n      <td>0.0</td>\n      <td>2.400391</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>112</td>\n      <td>3</td>\n      <td>96.977997</td>\n      <td>1</td>\n      <td>0</td>\n      <td>10.379939</td>\n      <td>3.800781</td>\n      <td>0.0</td>\n      <td>2.400391</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>113</td>\n      <td>0</td>\n      <td>159.643005</td>\n      <td>1</td>\n      <td>0</td>\n      <td>11.517734</td>\n      <td>3.800781</td>\n      <td>0.0</td>\n      <td>2.400391</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>113</td>\n      <td>3</td>\n      <td>19.597000</td>\n      <td>1</td>\n      <td>0</td>\n      <td>11.517734</td>\n      <td>3.800781</td>\n      <td>0.0</td>\n      <td>2.400391</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>114</td>\n      <td>0</td>\n      <td>324.750000</td>\n      <td>1</td>\n      <td>0</td>\n      <td>11.847138</td>\n      <td>3.800781</td>\n      <td>0.0</td>\n      <td>2.400391</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>114</td>\n      <td>3</td>\n      <td>100.000000</td>\n      <td>1</td>\n      <td>0</td>\n      <td>11.847138</td>\n      <td>3.800781</td>\n      <td>0.0</td>\n      <td>2.400391</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>115</td>\n      <td>0</td>\n      <td>201.542999</td>\n      <td>1</td>\n      <td>0</td>\n      <td>11.773110</td>\n      <td>3.800781</td>\n      <td>0.0</td>\n      <td>2.400391</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>116</td>\n      <td>0</td>\n      <td>69.300003</td>\n      <td>1</td>\n      <td>0</td>\n      <td>10.525837</td>\n      <td>3.800781</td>\n      <td>0.0</td>\n      <td>2.400391</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>117</td>\n      <td>0</td>\n      <td>16.306101</td>\n      <td>1</td>\n      <td>0</td>\n      <td>9.647950</td>\n      <td>3.800781</td>\n      <td>0.0</td>\n      <td>2.400391</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>117</td>\n      <td>3</td>\n      <td>19.680901</td>\n      <td>1</td>\n      <td>0</td>\n      <td>9.647950</td>\n      <td>3.800781</td>\n      <td>0.0</td>\n      <td>2.400391</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>118</td>\n      <td>0</td>\n      <td>117.199997</td>\n      <td>1</td>\n      <td>0</td>\n      <td>11.837303</td>\n      <td>3.800781</td>\n      <td>0.0</td>\n      <td>2.400391</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 15
    }
   ],
   "source": [
    "train_df.head(20)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "114"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 16
    }
   ],
   "source": [
    "# Features & Target Varibales\n",
    "target = np.log1p(train_df[\"meter_reading\"])\n",
    "features = train_df.drop('meter_reading', axis = 1)\n",
    "del train_df\n",
    "gc.collect()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "c:\\users\\administrator\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\lightgbm\\basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n  warnings.warn('Using categorical_feature in Dataset.')\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 1.11239\tvalid_1's rmse: 1.26353\n",
      "[50]\ttraining's rmse: 0.893486\tvalid_1's rmse: 1.13278\n",
      "[75]\ttraining's rmse: 0.823474\tvalid_1's rmse: 1.11738\n",
      "[100]\ttraining's rmse: 0.786152\tvalid_1's rmse: 1.11798\n",
      "[125]\ttraining's rmse: 0.760096\tvalid_1's rmse: 1.1213\n",
      "Early stopping, best iteration is:\n[87]\ttraining's rmse: 0.803727\tvalid_1's rmse: 1.11641\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 1.11881\tvalid_1's rmse: 1.22041\n",
      "[50]\ttraining's rmse: 0.901736\tvalid_1's rmse: 1.0668\n",
      "[75]\ttraining's rmse: 0.839297\tvalid_1's rmse: 1.03927\n",
      "[100]\ttraining's rmse: 0.808011\tvalid_1's rmse: 1.03175\n",
      "[125]\ttraining's rmse: 0.785606\tvalid_1's rmse: 1.03051\n",
      "[150]\ttraining's rmse: 0.767829\tvalid_1's rmse: 1.03221\n",
      "Early stopping, best iteration is:\n[123]\ttraining's rmse: 0.787144\tvalid_1's rmse: 1.03028\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[25]\ttraining's rmse: 1.08891\tvalid_1's rmse: 1.27118\n",
      "[50]\ttraining's rmse: 0.849451\tvalid_1's rmse: 1.15355\n",
      "[75]\ttraining's rmse: 0.775289\tvalid_1's rmse: 1.14605\n",
      "[100]\ttraining's rmse: 0.739234\tvalid_1's rmse: 1.14909\n",
      "Early stopping, best iteration is:\n[70]\ttraining's rmse: 0.784094\tvalid_1's rmse: 1.14491\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# KFold LightGBM Model\n",
    "categorical_features = [\"building_id\", \"site_id\", \"meter\", \"primary_use\", \"is_holiday\", \"weekend\"]\n",
    "params = {\n",
    "    \"objective\": \"regression\",\n",
    "    \"boosting\": \"gbdt\",\n",
    "    \"num_leaves\": 1280,\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"feature_fraction\": 0.85,\n",
    "    \"reg_lambda\": 2,\n",
    "    \"metric\": \"rmse\",\n",
    "}\n",
    "\n",
    "kf = KFold(n_splits=3)\n",
    "models = []\n",
    "for train_index,test_index in kf.split(features):\n",
    "    train_features = features.loc[train_index]\n",
    "    train_target = target.loc[train_index]\n",
    "    \n",
    "    test_features = features.loc[test_index]\n",
    "    test_target = target.loc[test_index]\n",
    "    \n",
    "    d_training = lgb.Dataset(train_features, label=train_target,categorical_feature=categorical_features, free_raw_data=False)\n",
    "    d_test = lgb.Dataset(test_features, label=test_target,categorical_feature=categorical_features, free_raw_data=False)\n",
    "    \n",
    "    model = lgb.train(params, train_set=d_training, num_boost_round=1000, valid_sets=[d_training,d_test], verbose_eval=25, early_stopping_rounds=50)\n",
    "    models.append(model)\n",
    "    del train_features, train_target, test_features, test_target, d_training, d_test\n",
    "    gc.collect()\n",
    "       "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "19"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 18
    }
   ],
   "source": [
    "del features, target\n",
    "gc.collect()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% \n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Memory usage of dataframe is 954.38 MB\n",
      "Memory usage after optimization is: 199.59 MB\nDecreased by 79.1%\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# Load test data\n",
    "test_df = pd.read_csv('F:\\deeplearning_dataset\\\\ashrae-energy-prediction\\\\test.csv')\n",
    "row_ids = test_df[\"row_id\"]\n",
    "test_df.drop(\"row_id\", axis=1, inplace=True)\n",
    "test_df = reduce_mem_usage(test_df)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "27"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 21
    }
   ],
   "source": [
    "# Merge Building Data\n",
    "test_df = test_df.merge(building_df,left_on='building_id',right_on='building_id',how='left')\n",
    "del building_df\n",
    "gc.collect()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "c:\\users\\administrator\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:16: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\nof pandas will change to not sort by default.\n\nTo accept the future behavior, pass 'sort=False'.\n\nTo retain the current behavior and silence the warning, pass 'sort=True'.\n\n  app.launch_new_instance()\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": [
      "Memory usage of dataframe is 19.25 MB\nMemory usage after optimization is: 9.05 MB\nDecreased by 53.0%\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# Fill Weather Information\n",
    "weather_df = pd.read_csv('F:\\deeplearning_dataset\\\\ashrae-energy-prediction\\weather_test.csv')\n",
    "weather_df = fill_weather_dataset(weather_df)\n",
    "weather_df = reduce_mem_usage(weather_df)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "19"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 23
    }
   ],
   "source": [
    "# Merge Weather Data\n",
    "test_df = test_df.merge(weather_df,how='left',on=['timestamp','site_id'])\n",
    "del weather_df\n",
    "gc.collect()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "# Features Engineering\n",
    "test_df = features_engineering(test_df)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "c:\\users\\administrator\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:4: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n  after removing the cwd from sys.path.\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# prediction\n",
    "results = []\n",
    "for model in models:\n",
    "    if  results == []:\n",
    "        results = np.expm1(model.predict(test_df, num_iteration=model.best_iteration)) / len(models)\n",
    "    else:\n",
    "        results += np.expm1(model.predict(test_df, num_iteration=model.best_iteration)) / len(models)\n",
    "    del model\n",
    "    gc.collect()\n",
    "       "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "del test_df, models\n",
    "gc.collect()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%    \n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# submission\n",
    "results_df = pd.DataFrame({\"row_id\": row_ids, \"meter_reading\": np.clip(results, 0, a_max=None)})\n",
    "del row_ids,results\n",
    "gc.collect()\n",
    "results_df.to_csv(\"submission.csv\", index=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results_df.head(20)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}